{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yti8I_My_B8m",
        "ZKXAkp08_QVC",
        "DkZuZho1Elld",
        "Fnlb1HgNk5pX",
        "Mbkwyo4SyHVw",
        "xGh1wZxRxZ0Y",
        "l96-cPxxyUMc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "yti8I_My_B8m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxFjmL-L-xOi",
        "outputId": "678e6609-ded0-4d30-9e20-d3a3f25f7621"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "## Importing all libraries\n",
        "import gc\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "import torch.nn as nn\n",
        "import re\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import gc\n",
        "from torch.utils.data import Dataset, DataLoader , TensorDataset\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "10cNEknZ-80p"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize variables"
      ],
      "metadata": {
        "id": "pUpuqCed_Hsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "input_file_path = \"sample_data/train\"\n",
        "dev_file_path = \"sample_data/dev_niu\"\n",
        "test_file_path = \"sample_data/test_niu\"\n",
        "\n",
        "## Custom params\n",
        "unk_token='__UNK__'\n",
        "dataLoader_batch_size = 5 \n",
        "tag_embedding_size = 1\n",
        "\n",
        "## Hyper-params as per HW4 pdf\n",
        "word_embedding_size = 100 \n"
      ],
      "metadata": {
        "id": "1QhHsia9_LWr"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Device variable"
      ],
      "metadata": {
        "id": "ImMDzEvyzYHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# #If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "# if is_cuda:\n",
        "#     device = torch.device(\"cuda\")\n",
        "#     print(\"GPU is available\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     print(\"GPU not available, CPU used\")\n",
        "\n",
        "device = torch.device(\"cuda\")\n"
      ],
      "metadata": {
        "id": "qdwn8QVTzahy"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "ZKXAkp08_QVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to sort dictionary in desc order\n",
        "def orderDictionary(d, reverse = False):\n",
        "  return dict(sorted(d.items(), key = lambda x: x[1], reverse = reverse))"
      ],
      "metadata": {
        "id": "nJpSSqFu_STK"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dictionary\n",
        "def create_vocabulary(file_path):\n",
        "    dictionary = dict()\n",
        "    # We removed punctuations to increase accuracy\n",
        "    train_file = open(file_path, \"r\")\n",
        "    for line in train_file:\n",
        "        # If line is not a blank line, do further processing  \n",
        "        if(line.strip()):\n",
        "            line = line.strip()\n",
        "            word = line.split(\" \")[2]\n",
        "            if word in dictionary:\n",
        "                dictionary[word] = dictionary[word] + 1\n",
        "            else:\n",
        "                dictionary[word] = 1\n",
        "            \n",
        "\n",
        "    # Order the dictionary in descending order\n",
        "    sorted_dict = orderDictionary(dictionary, True)\n",
        "\n",
        "    # @TODO - Check if we need unknown counts at all? - Might not need, we are explicitly considering UNK tag\n",
        "\n",
        "    return sorted_dict "
      ],
      "metadata": {
        "id": "u259ceNn_Tj3"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sentence_lists(file_path):\n",
        "  file = open(file_path, \"r\")\n",
        "  master_data = []\n",
        "  master_tags = []\n",
        "  sentence = []\n",
        "  tags = []\n",
        "  for line in file:\n",
        "      # If line is not a blank line, do further processing  \n",
        "      if(line.strip()):\n",
        "        line = line.strip()\n",
        "        word = line.split(\" \")[1]\n",
        "        sentence.append(word)\n",
        "        t = line.split(\" \")[2]\n",
        "        tags.append(t)\n",
        "      else:\n",
        "        # We know a line is done \n",
        "        master_data.append(sentence)\n",
        "        master_tags.append(tags)\n",
        "        sentence = []\n",
        "        tags = []\n",
        "\n",
        "  return master_data, master_tags    "
      ],
      "metadata": {
        "id": "nIosOvpX_Xfd"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertWordsToVectors(vocab,text):\n",
        "    \n",
        "    vectors = []\n",
        "    unk_ID = vocab[unk_token]\n",
        "    for word in str(text).split():\n",
        "\n",
        "    # if the word is not in vocab_dict, then assign UNK\n",
        "      word_ID = vocab.get(word, unk_ID)\n",
        "      vec = np.zeros((word_embedding_size,), dtype=np.float32)\n",
        "      vec[0] = word_ID\n",
        "      vectors.append(vec)\n",
        "\n",
        "    return vectors  "
      ],
      "metadata": {
        "id": "e47ik76-CJdL"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertNERTagsToVectors(ner_vocab, text):\n",
        "    \n",
        "    vectors = []\n",
        "    for i in range(0,len(text)):\n",
        "      tag = text[i]\n",
        "      # if the tag is not in ner_tag_list, then assign UNK\n",
        "      tag_ID = ner_vocab.get(tag)\n",
        "      vec = np.zeros((tag_embedding_size,), dtype=np.float32)\n",
        "      vec[0] = tag_ID\n",
        "      vectors.append(vec)\n",
        "\n",
        "    return vectors \n"
      ],
      "metadata": {
        "id": "z4l2_PQzrD61"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dStackAndMove(arr):\n",
        "  arr = np.dstack(arr)  \n",
        "  arr = np.moveaxis(arr, -1, 0)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "IIfcZ3gzHBwx"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a dictionary of all unique NER tags from Training data"
      ],
      "metadata": {
        "id": "E8R4fs5w_cQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task1: Create dictionary of all unique NER tags\n",
        "ner_tag_dict = create_vocabulary(input_file_path)"
      ],
      "metadata": {
        "id": "LCxRBfKO_dNT"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make data list from Train, Dev and Test data"
      ],
      "metadata": {
        "id": "d7UtNqNZ_zuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "master_train_data, master_train_tags = create_sentence_lists(input_file_path)\n",
        "master_dev_data, master_dev_tags = create_sentence_lists(dev_file_path)"
      ],
      "metadata": {
        "id": "7A65Dz4V_0fa"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Vocabulary from all words in Training data file"
      ],
      "metadata": {
        "id": "MsbUGRVR_6To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1:\n",
        "vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2} \n",
        "ner_vocab = {}\n",
        "for i in range(0,len(master_train_data)):\n",
        "    # If line is not a blank line, do further processing  \n",
        "    sentence = master_train_data[i]\n",
        "    tag = master_train_tags[i]\n",
        "    for word in sentence:\n",
        "      # We send the line to training model\n",
        "      if word not in vocab:\n",
        "        vocab[word] = len(vocab)\n",
        "    for t in tag:\n",
        "      if t not in ner_vocab:\n",
        "        ner_vocab[t] = float(len(ner_vocab))\n",
        "\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4lVdnoT_7dP",
        "outputId": "d482c30f-c4fa-46f1-8f99-70efebf8aca7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert individual word in each sentence to an embedding of size 1 x k=100"
      ],
      "metadata": {
        "id": "Wuf_Wr9yA0Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert lists into dataframe for ease in further processing\n",
        "\n",
        "text_labels_df = pd.DataFrame({'Text': master_train_data, 'Labels': master_train_tags})\n",
        "text_labels_df['Text'] = text_labels_df['Text'].apply(lambda x: convertWordsToVectors(vocab,x))   \n",
        "text_labels_df['Labels'] = text_labels_df['Labels'].apply(lambda x: convertNERTagsToVectors(ner_vocab,x))   \n",
        "print(text_labels_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feJjIhnoA_I7",
        "outputId": "54b2f5e2-15d1-4918-f42d-79c6cd5580bf"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    Text  \\\n",
            "0      [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "1      [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "2      [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "3      [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "4      [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "...                                                  ...   \n",
            "14981  [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "14982  [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "14983  [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "14984  [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "14985  [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "\n",
            "                                                  Labels  \n",
            "0      [[0.0], [1.0], [2.0], [1.0], [1.0], [1.0], [2....  \n",
            "1                                         [[3.0], [4.0]]  \n",
            "2                                         [[5.0], [1.0]]  \n",
            "3      [[1.0], [0.0], [6.0], [1.0], [1.0], [1.0], [1....  \n",
            "4      [[5.0], [1.0], [1.0], [1.0], [1.0], [0.0], [6....  \n",
            "...                                                  ...  \n",
            "14981                              [[1.0], [1.0], [1.0]]  \n",
            "14982                                     [[1.0], [1.0]]  \n",
            "14983                       [[0.0], [1.0], [0.0], [1.0]]  \n",
            "14984                                     [[1.0], [1.0]]  \n",
            "14985                       [[0.0], [1.0], [0.0], [1.0]]  \n",
            "\n",
            "[14986 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting numeric sentences to tensors"
      ],
      "metadata": {
        "id": "DkZuZho1Elld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(text_labels_df['Text'][0]) "
      ],
      "metadata": {
        "id": "mPJMINO_HXpg"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_labels_df['Text'] = text_labels_df['Text'].apply(lambda x: torch.tensor(x))\n",
        "text_labels_df['Labels'] = text_labels_df['Labels'].apply(lambda x: torch.tensor(x))\n",
        "print(text_labels_df['Labels'][0].shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIGqc_McEreM",
        "outputId": "83647539-59f9-4614-ea10-450eae13fe3e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a dataset object for using dataloader"
      ],
      "metadata": {
        "id": "Fnlb1HgNk5pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMDataset(Dataset):\n",
        "    def __init__(self, text, labels):\n",
        "        self.labels = labels\n",
        "        self.text = text\n",
        "\n",
        "        ## SENTENCE PADDING\n",
        "        self.text = pad_sequence(self.text, batch_first=True)\n",
        "        self.labels = pad_sequence(self.labels, batch_first=True, padding_value= -1 )\n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "            return len(self.text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "            label = self.labels[idx]\n",
        "            text = self.text[idx]\n",
        "            #sample = {\"Text\": text, \"Class\": label}\n",
        "            return text,label"
      ],
      "metadata": {
        "id": "91iIKdXck9nO"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing a DataLoader"
      ],
      "metadata": {
        "id": "nvAyIdjfmZFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataLoader = DataLoader(BiLSTMDataset(text_labels_df['Text'],text_labels_df['Labels']), batch_size=dataLoader_batch_size, shuffle=True) \n"
      ],
      "metadata": {
        "id": "5XlmE95JmYRe"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a BiLSTM class"
      ],
      "metadata": {
        "id": "8KmD4VBYxK2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    # target_size is no_of_tags. So, our output from linear layer must be probabilty of tag being any one of the no_of_tags (here: 9) tags\n",
        "    def __init__(self, vocab_len, input_size, hidden_size, num_layers, linear_output_dim, batch_size): # WE have to tune batch-size as hyper-param\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.linear_output_dim = linear_output_dim\n",
        "\n",
        "        ## Individual layer structures\n",
        "        # 1. Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_len, input_size, padding_idx = 0)\n",
        "\n",
        "        # 2. Single LSTM layer that is bi-directional\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # 3. Linear layer\n",
        "        self.fc = nn.Linear(hidden_size*2, linear_output_dim)\n",
        "        \n",
        "        # 4. ELU (we add an activation function in forward pass)\n",
        "        self.elu = nn.ELU()\n",
        "\n",
        "        # 5. We define the DropOUT layer here \n",
        "        self.dropout = nn.Dropout(0.33)\n",
        "\n",
        "        ## 6. - Not sure if we have to include this or not\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    #########################################################################################\n",
        "    def forward(self, x):\n",
        "        # Embedding layer - convert input to sequence of dense vectors\n",
        "\n",
        "        #print(\"PRE Embedding is: \",x.shape)\n",
        "        embedded = self.embedding(x)\n",
        "        embedded = embedded[:, :, 0, :]\n",
        "        #print(\"Embedding is: \",embedded.shape)\n",
        "\n",
        "        # Post-padding is needed as all sentences are not of same length, we consider a batch\n",
        "        # a batch has some list of sentences, we find the longest sentence \n",
        "        # We post-pad rest of the sentences until we reach length of the longest one\n",
        "        \n",
        "        seq_lengths = []\n",
        "        #print(\"Our batch ssize: \",len(x))\n",
        "        for i in range(0,len(x)):\n",
        "          seq_lengths.append(input_size)\n",
        "\n",
        "        #print(\"Seq lengths: \",seq_lengths)\n",
        "        seq_lens = torch.Tensor(seq_lengths)\n",
        "\n",
        "        ### SHOUMIK ::: REMMOVE THE ENFORE-SORTED VARIABLE FROM HERE\n",
        "        packed_embedded = pack_padded_sequence(embedded, seq_lens ,batch_first= True)\n",
        "        #packed_embedded = pack_padded_sequence(embedded, x.to('cpu'), enforce_sorted=False, batch_first= True) # we have to pass tensor also 'x'\n",
        "        #print(\"Packed Embedding is: \",len(packed_embedded))\n",
        "        \n",
        "        # BiLSTM layer\n",
        "        # num_layers*2 => here as we have a BiLSTM we multiple by 2 else 1\n",
        "        # h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "        # c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "        # out, _ = self.lstm(embedded, (h0, c0))\n",
        "\n",
        "        # (2, 7 ,256)\n",
        "        # co: (2,7,256)\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        # print(\"Hidden shape h0: \",h0.shape)\n",
        "        # print(\"Hidden shape c0: \",c0.shape)  \n",
        "        \n",
        "        out, _ = self.lstm(packed_embedded, (h0, c0))\n",
        "        #print(\"OUT from self.lstm: \",out)\n",
        "\n",
        "        # This is needed for the embeddings, we have to reduce the train time too!\n",
        "        output_unpacked, output_lengths = pad_packed_sequence(out, batch_first=True)\n",
        "        #print(\"UNPACKED OUT from self.lstm: \",output_unpacked.shape)\n",
        "\n",
        "        # Concatenate the final output of the forward and backward LSTM\n",
        "        out1 = torch.cat((output_unpacked[:, -1, :self.hidden_size], output_unpacked[:, 0, self.hidden_size:]), dim=1)\n",
        "        \n",
        "        #print(\"INPUT to Linear:: \",out1.shape)\n",
        "        # Output layer - Linear\n",
        "        out2 = self.fc(out1)\n",
        "\n",
        "        # print(\"Dimesnions from linear layer output: \",out2.shape)\n",
        "\n",
        "        ## See if adding dropout here works or not\n",
        "        dropout_op = self.dropout(out2)\n",
        "\n",
        "        # Then we apply ELU activation\n",
        "        elu_act = self.elu(dropout_op) \n",
        "\n",
        "        ## WHEN WE USE CROSS ENTROPY LOSS, WE MIGHT NOT NEED THIS SOFTMAX LAYER\n",
        "        #target_output = elu_act\n",
        "        #target_output = self.sm(elu_act)\n",
        "        #print(\"Elu activation step completed\")\n",
        "\n",
        "\n",
        "        #print(\"Probability target output: \",target_output)\n",
        "        #print(\"Probability target output size: \",target_output.shape)\n",
        "\n",
        "        #sigmoid function\n",
        "        sig_out = self.sigmoid(elu_act)\n",
        "        \n",
        "        #print(\"sig_out dimensions: \",sig_out.shape)\n",
        "        # reshape to be batch size first\n",
        "        #sig_out = sig_out.view(num_classes, -1)\n",
        "        #sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        result = sig_out\n",
        "        #print(\"Probability target output size AFTER SIGMOID: \",sig_out.shape)\n",
        "\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "-wPOuvRFxXRR"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Parameters"
      ],
      "metadata": {
        "id": "Mbkwyo4SyHVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Model variables\n",
        "input_size = 100 ## Given HP - embedding dim = 100\n",
        "hidden_size = 256 # Given HP - LSTM hidden dim\n",
        "num_layers = 1 # Number of LSTM layers\n",
        "num_classes = len(ner_tag_dict) # ASSUMING IT IS THE SIZE OF NER VOCAB WE CREATED,i,e 9\n",
        "batch_size = 5 # @TODO - Hyperparam - we find the best\n",
        "linear_output_dim = 128\n",
        "max_epochs = 1 #@ TODO - Hyper-param tuning needed\n",
        "lrate = 0.01 #@ TODO - Hyper-param tuning needed"
      ],
      "metadata": {
        "id": "HItPDjgQyKa_"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the model"
      ],
      "metadata": {
        "id": "xGh1wZxRxZ0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm = BiLSTM(len(vocab), input_size, hidden_size, num_layers, linear_output_dim, batch_size) "
      ],
      "metadata": {
        "id": "LN3vnoUHxcal"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimiser and Loss function"
      ],
      "metadata": {
        "id": "l96-cPxxyUMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we include optimizer\n",
        "optimizer = torch.optim.SGD(bilstm.parameters(), lr=lrate)\n",
        "\n",
        "# @TODO - Change this value Define the loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = -1)\n"
      ],
      "metadata": {
        "id": "E2OQrKogyXxv"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model for Task 1"
      ],
      "metadata": {
        "id": "eF9eYHVPyZyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(0,max_epochs):\n",
        "    print(\"Starting Epoch: \",epoch)\n",
        "    bilstm.train()\n",
        "    sum_loss = 0.0\n",
        "    total = 0\n",
        "    for input,label in trainDataLoader:\n",
        "      input = input.squeeze(0)\n",
        "      #print(\"Input shape after squeeze: \",input.shape)\n",
        "\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      y_pred = bilstm(input.to(device).long())\n",
        "      reshaped_ypred = y_pred.sum(dim=1)\n",
        "      label = torch.squeeze(label).squeeze().squeeze()\n",
        "      label = label[:,0]#[:, :, 0, :]\n",
        "      #print(\"Reshaped ypred shape: \",reshaped_ypred.shape)\n",
        "      #print(\"lable shape :: \",label.shape)\n",
        "      loss = criterion(reshaped_ypred.to(device).long(), label.to(device).long()) \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      sum_loss += loss.item() \n",
        "      total = total + 1   \n",
        "\n",
        "    print(\"Printing Sum loss: \",sum_loss,\" total: \",total,\" and train_loss: \",sum_loss/total)    \n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "UiRX9CfJygIU",
        "outputId": "63048822-70f5-4441-e3f4-37bb3a21cf72"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Epoch:  0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-d0efd2bd1148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mreshaped_ypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-b3836d789327>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#print(\"PRE Embedding is: \",x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#print(\"Embedding is: \",embedded.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
          ]
        }
      ]
    }
  ]
}